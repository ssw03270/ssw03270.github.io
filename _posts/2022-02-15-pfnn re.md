---

layout: post
title: PFNN 세미나 준비

---

> 이전에 정리한 자료에 빠진 부분이 많아 다시 논문 리뷰를 하려고 한다.

-----

# 1. Introduction

PFNN은 실시간으로 가상의 캐릭터 애니메이션을 주어진 입력과 지형에 적합하게 만들어주는 작업을 대신해준다. 그러나 이를 위해서는 많고 높은 퀄리티의 데이터가 필요하고 이를 캡쳐하는 것에도 어려움이 생긴다. 

- 많은 데이터로부터 학습이 가능해야 함
- 수동으로 전처리를 요구하지 않아야 함
- 낮은 메모리 요구를 통한 실시간 실행이 빠르게 가능해야 함

그러나 기존의 다른 방식들은 위의 문제 사항 중 최소 하나 이상과 충돌하는 경향이 있었다.

이러한 문제점은 문제가 얼마나 더 복잡해지냐에 따라 발생한다. 점프, 등반, 다양한 걷기와 복잡한 지형이 추가되면 이를 해결하기 위해 고차원 학습이 가능한 모델이 필요해진다.

기술 발전 덕분에 이를 해결하기 위한 다양한 모델이 개발되었다. 그러나 대중적으로 사용되는 모델들은 이러한 문제 해결을 하는데 있어 문제가 있다.

- CNN: 각 계층에서 주어진 정보에 대하여 로컬 변환을 수행한다. 그리고 이러한 과정이 반복되기 때문에 output이 생성되기까지 input의 값이 변화한다. 이러한 형태는 input이 한 번에 주어지고 output 또한 한 번에 주어지는 문제 해결에는 도움이 된다. 그러나 플레이어의 행동에 미래의 input이 영향을 받을 것이기 때문에 이러한 방법은 적합하지 않다.
- RNN (LSTM): 이러한 모델은 미래에 주어질 input 하나만 있으면 되기 때문에 이러한 문제 해결에 적합하다. 그러나 예측한 값의 오류가 누적됨에 따라 긴 모션 데이터를 만들 때 문제가 발생하게 된다.

이처럼 현존하는 모델들의 문제점을 해결하기 위해 논문의 저자들은 PFNN이라는 이름의 새로운 모델을 제시했다. PFNN은 동작의 타이밍을 나타내는 phase function을 이용해 각 프레임에서 네트워크가 가질 가중치를 생성한다. PFNN은 여러 phase의 데이터가 뒤섞이지 않도록 하며, 대신 phase가 지남에 따라 원할하게 발전하는 회귀 함수를 구축했다. 

PFNN과 다른 모델과의 차이점을 비교하면 아래와 같다.

- CNN에 비해 PFNN의 구조는 실시간 이동 생성에 적합하다
- RNN에 비해 PFNN은 매우 안정적이며 복잡한 환경에서 사용자 상호작용의 표현이 가능하다.

일반적인 신경망 구조와 달리 PFNN은 phase function을 통해 모델의 가중치를 동적으로 변경한다. 이는 compact한 구조를 유지하면서 회귀의 표현력을 높인다. 이를 통해 지형 데이터와 모션 데이터가 결합된 고차원 데이터 셋에서도 학습이 가능하다.

또한 논문의 중간에 비디오 게임 환경에서 추출한 지형 데이터에 모션 캡쳐 데이터를 맞추는 프로세스에 관해서도 기술되어 있다.

# 2. Related Work

이 절에서 다루고자 하는 내용은 아래와 같다.

1. 이동 생성을 위한 data driven approach 검토
2. 환경과 상호작용하는 캐릭터 움직임 합성 방법 검토
3. 신경망 기반으로하여 매게 변수를 latent variables에 매핑하는 방법 검토 (먼 개소리지?)

## Data Driven Locomotion Synthesis

Linear base한 Principal Component Analysis(PCA)는 모션 데이터의 차원 수를 줄이고 적은 수의 입력을 통해 full body motion을 예측한다. global pca는 저차원의 데이터에서 넓은 범위의 모션 데이터를 생성하는 것에 어려움을 겪으며, 이러한 문제를 해결하기 위해 2005년, 2011년에 local pca를 이용한 full body motion 예측에 관한 연구가 진행되었다. 그러나 이러한 구조는 훈련과 런타임을 위해 상당한 양의 데이터 전처리와 계산을 필요로 했다.

kernel based approache는 이전의 선형적인 방법의 한계점을 극복하고 비선형적 데이터를 고려하는 게 가능해졌다. 서로 다른 locomotion의 합성을 위해 방사형 기저 함수(RBF)와 가우시안 프로세스(GP)가 사용되었다. PCA의 일종인 Gaussian Process Latent Variable Models(GPLVM)은 저차원 데이터에서 IK의 중복 문제를 해결했다. kernel based approache는 공분산 행렬의 저장과 반전을 위해 높은 메모리 비용으로 인해 어려움을 겪는다. 보간을 위한 샘플 수를 줄이는 local GP가 제언되었지만 인간의 움직임과 같은 고차원적 데이터와 함께 사용될 때, precomputation과 run time을 위해 메모리 사용량이 큰 k-nearest neighbor search를 이용해야 한다.

신경망을 이용한 data driven motion sysnthesis는 높은 확장성과 런타임에서 효율성 덕분에 animation과 ML 등에서 많은 연구가 되었다. 2009년에 이동 중 신체의 다음 자세를 예측하기 위한 conditional Restricted Boltzmann Machine(cRBM)의 사용을 제안했다. 2015년에는 신체의 다음 자세를 예측하기 위해 LSTM을 적용하는 Encoder-Recurrent-Decoder 네트워크를 제안했다. 이러한 방법은 autoregressive models로 분류되며 이전 pose를 기반으로 캐릭터의 다음 pose를 예측한다. 이는 모든 프레임마다 캐릭터의 pose를 업데이트하기 때문에 게임 등에 적합하다. 이러한 장점에도 noise와 undder fitting으로 인해 평균 pose로 수렴하는 문제가 발생한다. 

본 논문에서는 사용자의 입력과 캐릭터의 이전 상태를 통해 캐릭터의 다음 pose를 예측하는 시계열 접근법이다.

## Interaction with the Environment

가상 환경에서 Automatic character controller는 실시간으로 장애물을 피하고 지형에 적응하도록 해준다. 이러한 접근법은 methods based on optimization과 shape matching으로 분류된다. 

Methods based on optimization과 sampling-based approaches, maximum a posteriori (MAP) estimates, 그리고 reinforcement learning techniques는 pose를 포함한 현재 캐릭터 상태와 지형과의 관계를 통해 다음 자세를 예측하는데 사용된다. 이것들은 각 상황에 따른 적합한 action인지 평가하기 위한 cost function이 필요하다. 이러한 방법들이 사실적인 움직을 생성할 것 같지만 cost function은 때때로 기하급수적으로 커지기 때문에 확장성이 높지 않다. 또한 kinematic 데이터를 사용하게 될 경우, k nearest neighbour search를 사용해야 된다. 이는 고차원 데이터의 확장성을 제한하는 요인이 된다. reinforcement learing을 이용한 2012년도의 논문에서는 GPLVM을 이용해 motion을 계산했지만 이들은 motion의 classfication이 필요했기에 이로인한 제한이 있다. deep reinforcement learing을 이용해 다차원 공간의 연산이 가능한 2016년도의 논문이 있으나 이들은 2차원에서의 motion만 가능하기 때문에 3차원이 안된다는 문제가 있다. 

주어진 환경에서 캐릭터를 제어하는 또 다른 방법은 환경의 기하학적 특성을 분석하고 pose나 동작을 적응시키는 것이다. 2006년에는 의자에 앉는 등의 접촉이 많은 행동에 대한 논문이 있었다. 2011년에는 캐릭터가 특정 작업을 수행하기 위한 위치를 찾기 위해 무차별적으로 탐색하는 방법에 대한 논문을 제시했다. 이외에도 다양한 논문이 존재한다. 그러나 이러한 방법들은 캐릭터가 새로운 지형을 만났을 때 빛을 발하지 못한다. 미리 지형에 대한 심층적인 분석이 필요하기 때문이다. 논문의 저자가 제시한 방법은 지형에 대한 기하학적 regression이므로 이러한 한계점을 극복할 수 있었다.

이 논문의 장점: 지형에 대한 기하학적 regression이므로 미리 지형에 대한 심층적 분석이 필요하지 않다.

## Mapping User Parameters to Latent Variables

많은 사람들은 합성 중에 사용자가 제어 가능하도록 이미지의 시점이나 조명 조건(parameter)을 latent variable과 매핑되는 것을 희망한다. 2015년에는 얼굴 이미지의 시점과 조명 조건을 variational autoencoder의 hidden unit에 매핑하는 기법을 제안했다. 2013년에는 latent variable이 신경망의 가중치를 직접 매개 변수화하는 multiplicative network를 제안했다. 이러한 네트워크는 latent variable이 global effect를 끼치면 매우 효과적이다. 논문의 저자는 이러한 방법이 캐릭터의 이동에 적용 가능하다는 것을 파악했고 이러한 공통 latent variable로 phase를 사용했다. 

phase를 사용한 이유: latent variable이 global한 effect가 가능할 때 매우 효과적임을 파악했고 이것이 캐릭터의 이동에 적용 가능하기 때문

# 3. SYSTEM OVERVIEW

![image](https://user-images.githubusercontent.com/62225673/154209020-21d44dc8-e3f5-416c-ac45-19e3cd43fa3d.png)

위 사진은 PFNN의 visual diagram이다. phase function 이라는 위상 p의 주기적 함수에 의해 네트워크의 가중치가 계산되는 신경망 구조다. input x에는 캐릭터의 이전 자세와 사용자의 컨트롤이 포함된다. output y에는 phase의 변화와 캐릭터의 현제 자세, 그리고 기타 추가적인 것이 들어가는데 이 부분은 추후 기술된다. 

![image](https://user-images.githubusercontent.com/62225673/154209788-53c2ed84-21a3-46a4-95a3-35deb32bad89.png)

이들의 시스템은 세 가지 단계로 구성된다.

- preprocessing stage: training data 준비, 사용자가 제공할 컨트롤에 관한 변수 추출, 이외에도 heightmap을 이용해 캡쳐된 모션 데이터를 지형 데이터에 맞추는 작업
- training stage: 각 프레임에서 주어진 컨트롤에 관한 변수를 이용해 캐릭터의 움직임을 생성할 수 있도록 PFNN 훈련
- runtime stage: PFNN의 input 변수로는 사용자의 컨트롤 뿐만 아니라 환경으로부터도 수집되며, 캐릭터의 움직임을 결정하기 위해 이들이 만든 시스템에 입력된다.

# 4. DATA ACQUISITION & PROCESSING

이번 섹션에서는 모션 캡쳐를 한 방법과 시스템의 학습을 위해 컨트롤에 관한 변수를 어떻게 추출했는지 기술된다. 그리고 모션 데이터를 지형 데이터에 어떻게 맞췄는지에 대한 부분도 나온다. 마지막으로 시스템에 대한 전체적인 요약이 들어간다.

## 4.1 Motion Capture and Control Parameters

모션 데이터가 촬영되면 phase, gait, 신체의 궤적, 궤적에 따른 지형과의 높이 차이가 계산되거나 수동으로 label 된다.

### Motion Capture

locomotion의 긴 sequence를 촬영할 때, 다양한 gait와 facing direction을 기록했다. 또한 스튜디오에 장애물과 경사면 등을 설치했다. 그리고 다양한 속도와 방법 그리고 장애물을 이용해 walking, jogging, running을 기록했다. 그리고 높이가 다르거나 걸음의 길이가 다른 웅크리기나 점프를 했다. 한 시간 가량의 60프레임 raw motion data를 촬영했고 대략 1.5GB에 달한다. BHV와 같은 버전의 30개의 회전 가능한 관절이 있는 CMU 모션 캡쳐 데이터가 엉덩이 아래 땅으로부터 root transformation이 적용되어 사용되었다.


### Phase Labelling

phase는 data에서 label 되어 PFNN의 input으로 쓰인다. 또한 발이 지면과 접촉한 시간 별로 labeling을 하기 위해 발 뒤꿈치와 발가락 관절의 속도의 크기를 측정하여 속도가 어떤 임계값 아래로 내려가면 자동으로 분류되도록 하였다. 그러나 때때로 정확하게 측정되지 않는 경우도 있기에 수동으로 추가적인 작업을 진행했다. phase의 경우에는 오른발이 땅에 닿았을 때 0이고, 왼발이 땅에 닿았을 때 pi, 다시 오른발이 땅에 닿으면 2pi가 된다. 그리고 각 경우의 사이에 위치한 프레임들에 의해 보간된다. 

### Gait Labels

gait는 binary vector로 저장되어 semantic label를 제공했다. 이유는 두 가지 있다.

1. fast walk와 slow jog를 구분해야 했다. 데이터의 모호함을 제거할 필요가 있었다.
2. 특정 시나리오에서 특정 동작을 관찰하고 싶을 때가 많다. 캡쳐 중에 배우가 gait의 유형을 변경하지 않고 일정하게 유지한다면 작업을 단순화 할 수 있다.

### Trajectory and Terrain Height

캐릭터의 root transformation은 고관절의 중심을 바닥에 투영하여 추출한다. facing vector는 고관절 사이의 벡터와 어깨 관절 사이의 벡터를 평균화하고 위쪽 방향으로 cross product하여 계산했다. 시간이 지남에 따라 noise가 제거되어 점차 부드러워진다.

root transformation이 추출되고 지형과 모델이 맞춰지면, 지형 높이는 궤적의 바로 아래 뿐만 아니라, 중심점에서 25cm 떨어진 위치에서도 계산된다.

이러한 작업이 모두 끝나면 mirrored version을 만들어 추가로 저장한다.

## 4.2 Terrain Fitting

런타임동안 캐릭터가 환경의 기하학적 특성에 자동으로 적응하는 시스템을 만들기 위해서는 캐릭터가 다른 지형을 이동하는 것을 포함한 훈련 데이터가 필요하다. 모션 캡쳐 스튜디오에서 지형과 모션을 동시에 캡쳐하기는 어렵다. 따라서 이들은 비디오 게임 등에서 추출한 heightmap으로부터 맵 데이터베이스를 제작하는 방법을 제시했다. 이를 통해 지형과 관련된 parameter를 input으로 쓸 수 있도록 해준다.

본 논문에서 사용한 지형 정보는 Source Engine의 장면들에서 추출했다. 위에서 지형을 캡쳐하며, 인치당 1픽셀로 해상도를 설정했다. 그리고 맵의 전체 기하학적 정보를 heightmap 형태로 저장했다. 그리고 heightmap의 위치와 방향을 무작위로 회전시켜 3x3 크기의 2만개의 pathces를 얻었다. 얻은 pathces는 fitting process에서 사용된다.

fitting process는 두 가지 단계로 나뉜다.

1. 주어진 모션 데이터에 대하여 가장 적합한 patch 10개를 brute force 방법을 통해 찾는데, 이때 error function의 값이 가장 낮은 10개를 찾는다. 
2. 메쉬 editing 기술 중 하나인 Radial Basis Function을 이용하여 캐릭터의 발과 지면이 정확히 맞닿도록 편집한다.

각 motion cycle에 대해서, 왼쪽/오른쪽 발뒤꿈치와 발가락 관절의 수치인 J ∈ {lh rh lt rt }가 있다. 그리고 매 프레임 i번째마다 fi(lh), fi(rh), f(lt), f(rt) 각각으로부터 높이를 측정했다. 그리고 바닥과 접촉했는지 나타내는 이진 변수인 ci(lh), ci(rh), ci(lt)m ci(rt)를 계산했다. 그리고 바닥에 접촉한 시간동안 접촉면의 평균 위치를 찾아 각 patch의 중심을 이 위치로 옮겼다. 또한 각 patch에서, 각 관절 아래 지형과 높이 차이를 계산하여 hi(lh), hi(rh), hi(lt), hi(rt)로 나타낸다.

fitting error인 Efit는 아래와 같이 정의된다

- Efit = Edown + Eup + Eover

Edown은 발이 땅에 닿았을 때, 지형의 높이와 일치하도록 보장하는 역할이다. 

![image](https://user-images.githubusercontent.com/62225673/154421565-e5370200-b303-459e-866a-c70f26baaaa1.png)

Eup은 발이 땅에 닿았을 때, 항상 지형 위에 위치하도록 보장하는 역할이다.

![image](https://user-images.githubusercontent.com/62225673/154422301-93968657-351c-40c9-98ee-af8ef51a05f7.png)

Eover은 캐릭터가 점프할 때만 활성화된다. 그리고 지형과 발 사이의 거리가 l이하가 되도록 한다. l은 30cm 이하다. 이를 이용해 큰 장애물이 있는 곳에서는 큰 점프를, 작은 장애물이 있는 곳에서는 작은 점프가 가능해진다. 

![image](https://user-images.githubusercontent.com/62225673/154423682-11c195e5-13b5-4567-89f5-86cb70bc1add.png)


모든 patch에서 Efit을 계산한 이후, fitting error가 가장 적은 10개의 patch를 찾는다. 그리고 위에서 적었던 fitting process의 2번째 단계를 실행한다. 이번 단계에는 heightmap을 수정하여 발이 바닥에 잘 닿을 수 있도록 수정한다. 이는 간단한 버전의 Botsch and Kobbelt을 이용해 heightmap을 수정했다. 그리고 남은 terrain fit을 위해 linear kernel을 이용해 2D RBF를 적용했다. 그러나 편집이 필요한 경우가 많지 않기 때문에 어떤 방법이든 사용해도 상관 없다고 한다. 

fitting process를 끝낸 결과는 아래와 같다.

![image](https://user-images.githubusercontent.com/62225673/154426907-59e476be-454f-48ec-97c3-ead6044e4c3f.png)

## 4.3 System Input/Output Parameters

이번 절에서는 본 논문의 시스템에 쓰일 input과 output에 대하여 이야기할 것이다. 각 프레임 i 때마다 네트워크의 가중치를 계산하기 위해 phase p가 필요하다. input data xi에는 유저의 control parameter와 이전 프레임에서 캐릭터의 상태, 지형 parameter가 필요하다. 그리고 이것들이 계산되어 나온 결과물인 yi에는 현재 프레임에서 캐릭터의 상태, phase의 변화, root  transform의 이동, 다음 frame의 궤적 예측, IK post processing을 사용하기 위한 발 관절의 contact label이 나온다.

이번에는 input parameter xi에 대해 조금 더 자세히 다뤄보려고 한다. 이들이 사용하는 parameterization은 2016년도의 Motion Matching과 유사하다. 그러나 두 가지 부분에서 다르다. (확인되지 않은 부분이라 정확히 모름) 캐릭터의 root transform을 좌표계의 기준으로 삼아 캐릭터 관절의 좌표와 속도를 캐릭터의 상태로 취한다. 현재 프레임으로부터 주위 t=12개의 프레임을 확인한다. 이 프레임은 과거는 1초, 미래는 0.9초의 움직임을 포착한다. 샘플링된 주변 프레임에서 feature를 추출하는데 이 feature에는 캐릭터의 좌표와 방향 궤적이 들어있다. 그리고 이는 프레임 i 일 때,  root transform 기준이다. 캐릭터의 걸음 걸이는 이진 벡터로 주어지며, 이동 궤적 아래에 위치하는 지형의 높이와 25cm 떨어진 왼쪽과 오른쪽의 궤적이 추가적으로 포함된다. 

![image](https://user-images.githubusercontent.com/62225673/154633993-73dfc1a1-3490-46bc-ac6c-385d3bb19ed2.png)

위는 단일 프레임 i에 대한 input data xi다. 

- ti(p): 프레임 i일 때, 2차원 수평 평면에서 궤적의 좌표를 의미, R(2t)
- ti(d): 프레임 i 일 때, 2차원 수평 평면에서 궤적의 방향을 의미, R(2t)
- ti(h): 프레임 i일 때 ,왼쪽 오른쪽 가운데의 궤적 높이를 의미, R(3t)
- ti(g): 캐릭터의 걸음걸이를 나타내는 궤적을 의미, R(5t), 5차원의 이진 벡터로 표현
- ji-1(p): 이전 프레임에서 관절의 로컬 좌표, R(3j)
- ji-1(v): 이전 프레임에서 관절의 로컬 속도, R(3j)

j는 관절의 번호를 의미하며 최대 31개까지 있다. 추가적으로 ti(g)는 stading, walking, jogging, jumping, crouching 할 때 활성화된다. 

![image](https://user-images.githubusercontent.com/62225673/154635294-3cb1ba08-da01-45a3-adf6-27a524b32151.png)

위는 단일 프레임 i에 대한 output data yi다.

- ti+1(p): 다음 프레임에서 예측된 궤적의 좌표, R(2t)
- ti+1(d): 다음 프레임에서 예측된 궤적의 방향, R(2t)
- ji(p): 캐릭터의 root transform을 기준으로 한 관절의 로컬 좌표, R(3j)
- ji(v): 캐릭터의 root transform을 기준으로 한 관절의 로컬 속도, R(3j)
- ji(a): 캐릭터의 root transform을 기준으로 한 관절의 로컬 각도, R(3j)
- ^ri(x): facing direction에 기반한 root transform의 x 속도다, R
- ^ri(z): facing direction에 기반한 root transform의 z 속도다, R
- ^ri(a): upward direction에 기반한 root transform의 각속도다, R
- ^pi: phase의 변화, 즉 주기의 변화, R
- ci: 발과 접촉면의 레이블, R(4), 발뒤꿈치와 발가락 관절이 바닥에 닿았는지의 여부를 나타내는 이진 변수로 구성

# 5. PHASE-FUNCTIONED NEURAL NETWORK

PFNN은 가중치가 phase에 따라 사이클이 돌아가며 바뀌는 네트워크 구조다. 이들은 네트워크의 가중치를 만드는 함수를 phase function이라고 부르기로 했다. 그리고 이것은 Catmull-Rom spline으로 구성되어 있다. 5.1에서 신경망 구조에 대한 설명을, 5.2에서 phase function의 사용하여 생성한 가중치에 대하여, 5.3에서는 절차적 학습에 대하여 이야기 할 것이다.

## 5.1 Neural Network Structure

우선 3개의 레이어로 구성된 간단한 신경망을 만들었다. 

![image](https://user-images.githubusercontent.com/62225673/154638417-116a0f76-a237-45b6-b9d3-bb49f9ee0503.png)

![image](https://user-images.githubusercontent.com/62225673/154638735-8ae561d5-32c2-4dfa-ada4-c449104dba83.png)

h는 hidden unit의 개수를 의미한다. 본 논문에서는 512개로 설정했다. 그리고 activation function으로는 ELU를 사용했다. 아래는 해당 activation function의 식이다.

![image](https://user-images.githubusercontent.com/62225673/154641960-9b3c89a4-65a5-4979-8ee4-c9d7e50f51bc.png)

## 5.2 Phase Function

PFNN에서 네트워크 가중치인 α는 각 프레임마다 phase function에 의해 계산된다. phase function은 phase p와 parameters β를 입력으로 가진다. 식은 아래와 같다. 

![image](https://user-images.githubusercontent.com/62225673/154642355-8933947d-5f7f-4eec-8ead-5ec5d1095e31.png)

이론적으로, Θ는 무엇으로 설정해도 괜찮다. 다른 네트워크가 될 수도 있고 Gaussian Process여도 괜찮지만 이 논문에서는 cubic Catmull-Rom spline을 사용했다. 

Catmull-Rom spline에는 몇 가지 장점이 있다. control point의 시작점과 끝점을 같게 둠으로써 쉽게 하나의 싸이클을 만들 수 있다. 그리고 parameter의 수가 control point의 수와 비례한다. 그리고 input parameter p에 의해 부드럽게 변화한다. cubic Catmull-Rom spline을 고른 이유는 각 phase function의 controll point αk가 α의 특정 가중치를 나타내도록 하기 위함이다. 그리고 함수 Θ는 이러한 가중치들의 사이를 부드럽게 보간해준다. Θ는 신경망의 가중치 공간에 있는 1차원 순환 다양체 라고 생각하면 편하다. 이 다양체는 phase에 의해 매게변수화 된다. 이러한 의미에서 네트워크는 입력 매개변수에서 출력 매개변수로 회귀를 성공적으로 수행하는 신경망 가중치 공간에서 적절한 순환 다양체를 찾는 것이다.

이들은 4개의 control point와 cyclic spline만 있으면 충분히 시스템에서 요구하는 regression을 표현할 수 있음을 찾아냈다.

![image](https://user-images.githubusercontent.com/62225673/154682693-c9c700fc-b21e-4675-87b4-94e07d1c4ca6.png)

![image](https://user-images.githubusercontent.com/62225673/154682784-b33c3b7e-71be-4691-93e6-8ac9e76d99d0.png)

결과적으로 위와 같은 식을 표현하게 된다.

## 5.3 Train

각 프레임 i마다 xi, yi, 그리고 pi는 X, Y, P에 보관된다. 평균 x, y 와 표준편차 x, y는 정규화를 위해 사용된다. 정규화된 데이터는 xw, yw라는 추가적인 가중치에 의해 scaling 된다. 최상의 결과는 관절과 관련된 변수를 0.1이라는 값으로 scaling 하여 중요도를 낮춤으로써 만들어진다고 한다. 이를 통해 regression에서 trajectory의 영향을 증가시켜 더 나은 결과를 만들어낸다. 입력에 포함된 이진 변수는 정규화되어 있기 때문에 추가적인 가공을 하지 않는다. terrain fitting이 끝나고, 가장 결과가 좋은 10개의 patch를 찾았다면 400만개의 data point를 포함한 dataset을 얻게 된다.

네트워크를 훈련시키기 위해서는 주어진 control parameter X 및 phase parameter P에 대해 신경망 Φ의 함수로 해당하는 output Y를 생성할 수 있어야 한다. 따라서 train 하는 것은 phase function parameter인 β = {α0 α1 α2 α3}와 cost function에 관한 optimization problem이다. cost function은 아래와 같다.

![image](https://user-images.githubusercontent.com/62225673/154684777-33b0f4dd-991b-43f9-814c-a09a23eadc1f.png)

cost function의 첫 항은 regression 결과의 mean squared error다. 그리고 두 번째 항은 가중치가 너무 커지지 않도록 해주는 정규화 과정이다. 이는 γ에 의해 조절되며 본 논문에서는 0.01로 설정되어 있다.

이들은 β에 대한 cost function의 도함수를 자동으로 계산하는 Theano와 함께 stochastic gradient descent algorithm을 사용했다. Dropout도 적용하는데 이때 0.7로 설정했다. 그리고 모델의 mini batch size는 32다. 20번의 epoch를 돌렸다.

# 6. RUNTIME

runtime 동안 PFNN에는 매 프레임마다 phase p와 input x가 주어져야 한다. phase p는 시간이 지남에 따라 0에서 2pi까지 증가하면서 반복한다. neural network의 input x는 이전 프레임의 관절 좌표와 속도를 포함한다. 또한 이들은 과거와 미래의 궤적을 input으로 사용한다. 과거의 궤적은 단순히 기록된 정보를 이용하고 미래의 궤적은 조금 더 디테일한 설명이 필요하다. 이는 곧 이야기한다.

## Inputs Relating to Future Trajectories

미래의 궤적은 게임 패드의 컨트롤 스틱을 조작함으로써 생긴 궤적을 바탕으로 PFNN에 의해 계산된다. 

2016년의 Motion Matching 이라는 논문에서는 스틱의 위치를 바탕으로 캐릭터가 앞으로 가질 속도와 방향을 예측한다. 그리고 본 논문의 저자는 PFNN을 이용해 이전 프레임의 위치와 방향을 입력으로 속도와 방향을 예측한다. 이때 blending function은 아래와 같다.

![image](https://user-images.githubusercontent.com/62225673/155054985-b859bbae-abfc-4b47-ab4f-18f06118cd35.png)

궤적 t는 0에서 1까지의 값을 가진다. 그리고 1로 갈수록 더 먼 미래를 의미한다. τ 는 추가적인 bias로 캐릭터의 반응을 제어한다. 본 논문에서 τv는 속도를 블렌딩하기 위한 bias로 0.5로 설정하고 τd는 방향을 블렌딩하기 위한 편향으로 본 논문에서는 2.0으로 설정되어 있다. 캐릭터의 반응, 즉 갑작스러운 방향 전환 등이 아니고서야 대부분의 경우에는 아주 자연스럽게 반응성을 유지한다고 한다. 

또한 미래의 궤적에는 캐릭터가 취해야할 걸음걸이 뿐만 아니라 머리 위의 천장의 높이와 캐릭터가 점프를 해야하는지 혹은 위로 걸어올라가야하는지의 정보도 들어있다. 추가로 게임패드의 오른쪽 어깨 버튼을 통해 걸음걸이를 jog <-> run 으로 바꾼다. 그리고 지형에 따라 점프 동작을 활성화할지에 대한 정보도 있다.

일단 미래의 궤적을 도출해냈다면 주어진 궤적을 지형에 수직으로 투영하여 높이를 구하는데 이는 th를 구하기 위함이다. 이를 통해 y를 계산하기 위한 PFNN의 모든 input을 구성했다.

output y의 최종 관절 정보는 예측된 관절 좌표와 각도 j(p), j(a)에 의해 계산된다. 그리고 이 관절 정보는 발의 끌림 현상을 피하기 위해 두 개의 IK 관절에 의해 조작된다. root transform position과 rotation은 예측된 root translational and rotational velocities i(x), (z), i(a)에 의해 갱신된다. 이렇게 runtime의 과정은 끝이 나고 이러한 과정이 매 프레임마다 일어난다.

## Precomputation of the Phase Function

훈련이 완료되면, PFNN은 아주 적은 용량으로 β를 저장한다. 또한 phase function Θ은 일차원 함수기 때문에 milisecond 단위의 시간 밖에 걸리지 않는다. 그러나 어떤 경우에는 매우 느려질 수 있지만 이는 phase p가 고정된 범위인 0 ~ 2pi 안에 존재한다는 점을 바탕으로 사전에 계산을 함으로써 runtime에서의 딜레이를 방지한다. 

위처럼 precomputing을 위한 몇 가지 옵션이 존재한다. 이는 속도와 메모리 사용량 사이에서 선택을 하게 만든다. n = 50에 대해 Θ를 사전에 미리 계산함으로써 메모리 사용량을 n/4배 증가시키지만 Θ의 계산을 완전히 없엘 수 있다. 대조적으로 n = 10으로 샘플을 뽑게 된다면 샘플에 대한 부분 선형 보간법을 수행할 수 있다. 이를 통해 메모리 사용량을 줄일 수 있지만 부분적 선형 보간을 계산하는데 시간이 소비된다. 또는 runtime에 cubic Catmull-Rom spline을 평가하는 방법도 있다.

# 7. Result

이번 절에서는 여러가지 상황에 따른 이들이 만든 방법이 어떻게 적용되는지를 볼 것이다. 

![image](https://user-images.githubusercontent.com/62225673/155072355-0872df95-655a-40f7-9a8b-72a7072fdd30.png)

위는 평지에서 캐릭터가 회전, 속도 변환 등의 작업을 수행하는 모습이다. 이들의 시스템은 반응성을 유지하고 사용자 입력에 잘 적응하여 다양한 입력에 대해 자연스럽고 고품질의 모션을 생성한다. 

![image](https://user-images.githubusercontent.com/62225673/155072651-23217143-dd3d-4da3-92af-900b01932db3.png)

위는 거친 환경에서 캐릭터가 적절히 걸어가는 결과다. 필요한 상황에 따라 등반이나 점프 등의 행동을 한다. 

![image](https://user-images.githubusercontent.com/62225673/155072876-2eca447c-dfd1-4740-90e0-d42ea7dad05c.png)

위는 천장이 낮은 곳에서 캐릭터가 웅크리는 걸 볼 수 있다. 천장의 높이 t(g)를 적용함으로써 캐릭터가 여러 천장의 높이에 따라 적절히 웅크린 채 움직이게 된다. 

![image](https://user-images.githubusercontent.com/62225673/155073335-89b29bd5-84b5-412d-a0f8-008f70eda3a9.png)

때로는 게임 디자이너가 캐릭터가 하나의 상황에 대해 다른 움직임을 취하길 바란다. 이때 t(g)를 수정한다면 위 사진처럼 장애물을 기어오르는 대신 점프하는 것도 가능하다.

![image](https://user-images.githubusercontent.com/62225673/155073534-c800585b-a104-4250-96a3-fa13c6e1be87.png)

또는 위 그림과 같이 캐릭터가 군형을 잡는 동작을 취하는 것도 가능하다.

# 8. EVALUATION

이번 절에서는 여러 개의 신경망을 이용해 비교를 한다. 

![image](https://user-images.githubusercontent.com/62225673/155074010-a839a9ff-c433-4cc9-9802-78ba7953ad16.png)

ERD: Encoder Recurrent Decoder, GP: Gaussian Process

- (a): NN의 input으로 phase가 주어지지 않은 경우 
- (b): NN에 추가적인 input으로 phase가 주어진 경우
- (c): ERD network
- (d): 추가적인 input으로 phase가 주어진 ERD network
- (e): GP autoregressor
- (f): phase를 이용하는 GP autoregressor

위의 각 신경망에 대하여 공정한 평가를 위해 메모리 사용량이 동일하도록 가중치의 숫자를 조정해서 훈련시켰다. 

그러나 각 모델들은 전부 PFNN보다 못한 결과물을 내보냈다. 추가로 일부는 근본적으로 모션 데이터 생성이 불가능한 문제도 있었다. 그리고 성능 비교 표도 있다. 그리고 data driven terrain fitting model과 simple procedural model을 비교하여 발의 위치를 평가할 것이다. 마지막으로 미래 궤적의 생성 방법을 조정하여 이러한 변화가 시스템의 responsiveness와 following ability에 어떤 영향을 미치는지 평가할 것이다.

## Standard Neural Network

phase를 제공받지 않은 신경망을 사용할 경우, 시스템은 다른 phase의 모션을 잘못 학습하게 되고 캐릭터가 떠다니는 듯한 결과를 만들었다. 그러나 이들이 만든 PFNN은 동일한 phase에 대해서만 학습을 하기 때문에 이러한 문제를 겪지 않는다고 한다. 

![image](https://user-images.githubusercontent.com/62225673/155077015-4b72a1d8-a242-405c-a0bf-2a743458b428.png)

이러한 상황을 예방하기 위해 phase를 추가적으로 주는 방법도 있다. 그러나 학습이 진행됨에 따라 phase의 영향이 약해지고 다른 변수가 예측을 지배하게 되어 동작이 딱딱해진다. 결과는 위와 같다. 이는 dropout으로 인해 phase와 관련된 부분이 누락되어 발생하는 문제다. 이를 위해 각 신경망에 대해 phase가 주는 영향력을 확인했다. 그 결과 standard neural network에서 phase가 주는 영향력이 0.001인 것에 반해 PFNN이 주는 영향력은 0.05로 50배 가량 차이가 난다. 이때 영향력 수치는 phase의 변화에 따른 y의 변화다. phase에 대해 dropout을 하지 않는 방법이나 phase의 복사본을 입력으로 주는 방법도 있겠지만 이는 이들이 만든 해법에 비해 썩 깔끔하지는 못하다. 

## Encoder-Recurrent-Decoder Network

다음으로 RNN / LSTM 네트워크 구조의 변형인 ERD 네트워크와 PFNN을 비교한다. ERD 네트워크는 Φ을 취하여 중간 변환 과정을 LSTM의 반복 변환으로 만든다. ERD 네트워크는 memory가 존재하기 때문에 직접적으로 phase가 주어지지 않더라도 학습이 가능하다. 또한 중간중간 반복 과정을 수행하기 때문에 dying out 되는 시간을 지연시킨다. 

그러나 여전히 몇 가지 문제점이 존재한다. ERD 네트워크는 캐릭터가 정지했을 때의 phase를 관찰할 수 없고 이로인해 왼발 혹은 오른발 중 어떤 발로 걷기 시작할지 알 수 없다. 이로인해 두 발이 평균으로 수렴하거나 공중으로 뜨는 문제가 생긴다. 즉, phase는 모든 경우에 학습 되는 것은 불가능하며 이들과 같이 독립적으로 공급되어야 하는 hidden latent variable이다. 

d와 같이 phase를 추가적인 input으로 주는 것도 가능하고 이를 통해 결과물의 성능을 높일 수는 있지만 공중에 뜨는 문제를 해결하지는 못한다. 

## Autoregressive Gaussian Processes

두 가지 Gaussian Process와 비교하는 모습을 볼 거이다. 첫 번째로 이들은 GP에 phase가 추가적인 input으로 주어진 모델을 만들었다. 이러한 형태는 Gaussian Process Dynamic Model과 유사한 모습을 보인다. 만약 input control parameter를 latent variable로 고려한다면 자동적으로 학습되는 것이 아닌 수동으로 학습이 진행되어야 한다. 그리고 이러한 점은 GP over fitting을 야기한다. 왜냐하면 적은 양의 데이터가 주어지기 때문이다. 이로인해 시스템은 불안정해진다. 추가적으로 GP는 메모리의 경우 square order로, cost는 cubic order로 비용이 증가하기 때문에 복잡한 상황에서 적용할 수 없다. 평면에서의 움직임만 테스트 할 수 있었고 훈련 샘플은 3000개로 제한했다. 그러나 대용량 데이터 셋에서 runtime 성능과 메모리 비용이 좋지 않았다.

![image](https://user-images.githubusercontent.com/62225673/155085895-a0971b1d-e0bc-4cba-bea6-50b710e42348.png)

다음으로 phase space에 따라 10개의 서로 다른 위치에 대해 여러개의 독립적인 GP를 구성하고 runtime에 가장 적합한 두 개의 GP를 선택하고 결과를 보간하는 방법을 사용했다. 이는 PFNN과 유사한 결과를 보인다. 그러나 많은 데이터에 대한 학습이 불가하기 때문에 좋게 평가하지 않았다. 

## Performance 

![image](https://user-images.githubusercontent.com/62225673/155086168-cd54dfb1-ff27-4f53-b71e-f0acf3bcee38.png)

위 표를 통해 우리는 다양한 방법에 대해 비교가 가능하다. GP 기반의 기술들은 데이터의 용량, 메모리 사용량, runtime performance에 제한이 있다. constant approximation을 사용할 때, 다른 신경망 기반 기술과 런타임 성능은 비슷하지만 메모리 사용량이 더 높다. phase function의 full cubic Catmull Rom spline을 사용하면 메모리 사용량은 비슷하지만 런타임은 더 길어진다. 이들의 방법의 단점은 훈련 시간이 길다는 점이다. 

## Terrain Fitting

![image](https://user-images.githubusercontent.com/62225673/155088806-79248ad7-dcd7-4f4a-a71c-f410d98fd817.png)

위 사진을 통해 두 가지 terrain fitting process를 확인할 수 있다. 4.2절에서 설명한 mesh editing 기술을 이용해 평지를 발바닥이 맞닿은 것에 맞춰 변형시켰다. 그러나 이렇게 합성된 지형은 매끄럽고 큰 변화가 없다. 이러한 부드러운 지형에 over fitting된 캐릭터는 큰 바위 등의 거친 환경을 마주했을 때, odd motion을 생성한다. 자세한 사항은 부록을 참조하자.

## Responsiveness

![image](https://user-images.githubusercontent.com/62225673/155266902-451e269c-7adc-4888-9a28-5ec8dcaaebc8.png)

바로 위 그림을 통해 캐릭터의 반응성을 확인 할 수 있다. 미리 정의된 여러 경로를 만들고 캐릭터가 이를 따르도록 만들어줬다. 그리고 원하는 궤적과 실제 궤적 사이의 오차를 확인했고 이를 아래의 표를 통해 나타냈다.

![image](https://user-images.githubusercontent.com/62225673/155267079-470cd071-f4be-4358-a445-651982f65144.png)

섹션 6에서 설명한 변수를 조정함으로써 애니메이션의 품질을 낮추는 대신 반응성을 높일 수도 있다. 

# 9. DISCUSSIONS

전체적인 시스템의 아키텍처와 입출력 매개변수, 시스템의 한계에 대해 논의한다. 

## Network Architecture

이들의 모델은 dying out이나 불안정성의 문제를 겪지 않는다. 그리고 시계열 방식을 이용해 현실적인 움직임을 만든다. 이것은 시스템 설계를 통해 가능해진다. phase를 신경망 가중치에 독립적으로 적용 시킴으로써 dying out으로 인한 phase간의 혼합 문제를 해결했다. 또한 이를 통해 phase의 영향력이 훈련 및 런타임 때 효과적인 영향을 미치도록 하였다. 따라서 다른 네트워크와 비교할 때 나타난 phase의 혼합 및 영향력 감소 문제가 해결되었다.

이들의 모델은 512개의 hidden unit이 있는 두 개의 레이어와 입출력 레이어가 있다. 이러한 형태를 가지게 된 이유는 실시간 애니메이션 목적에 맞게 원하는 모션을 쉽게 계산할 수 있도록 네트워크를 최대한 단순하게 만들고자 하는 바람에서 비롯되었다. 또한 이렇게 탄생한 모델의 구조는 계산 효율성과 생성된 움직임의 퀄리티 사이의 가장 좋은 타협점이라 여긴다.

현재는 걷기와 관한 부분 밖에 PFNN에 학습되어 있지만 비순환 phase function을 체택함으로써 이 또한 해결 가능하다. 비순환 데이터의 시작을 0, 중간을 0.5, 마지막을 1로 설정하여 적절히 훈련한다면 PFNN을 통해 킥이나 펀치 등의 액션도 생성할 수 있다.

개념적으로 이들의 모델은 phase마다 개별적으로 학습한 것과 동일한 효과를 보인다. 네트워크의 무작위 가중치 초기화와 기타 요인 등으로 인해 의도했던 것과는 다른 모델이 탄생한다. 따라서 연속성이나 주기적인 성질이 보존되지 않고 움직임이 불안정해지는 것이다. 

## Control Parameters for Real-time Character Control

이들의 시스템은 모션 캡쳐 데이터와 주어진 임의의 환경을 통해 실시간 캐릭터 제어를 위해 설계되었다. 이를 위해 Motion Matching 이라는 2016년도의 논문에서 효과가 입증된 유사한 입력 매개 변수를 사용했다. 캐릭터의 궤적 아래 지형의 높이를 추출하여 환경과 관련된 입력을 찾는 동안 사용자 입력으로부터 미래의 궤적을 예측한다. 과거와 미래의 위치, 방향 및 지형 특성을 사용하면 모호하지 않은 고품질의 모션을 생성할 수 있다. 모션 스타일 등의 추가 입력 변수를 통해 추가 작업도 가능하다.

## Other Potential Parameterization

딥러닝을 통해 이러한 작업들에 조금 더 풍부한 입력을 사용할 수 있음을 발견했다. 예를 들어, 주변 지형의 깊이 또는 RGB 이미지를  환경과 관련된 입력으로 사용하고 이 입력을 추상화하기 위해 convolution layer를 사용하는 방법도 있다. 이는 꽤 흥미로운 접근 방법이고 특히 동작이 제한적이고 균형을 유지하기 위해 땅의 세부 사항이 필요한 로봇 공학에 도움이 되리라 생각한다. 이를 연구 초기 단계에 적용하려 했으나 몇 가지 문제점에 봉착했다. 첫째, CNN을 사용하는 것은 현재 사용하는 것보다 더 많은 데이터가 필요함을 알게 되었다. 또한 CNN을 사용하는 것은 더 복잡한 신경망 구조를 만들었고 이로 인해 컴퓨터 게임과 같은 런타임 시간을 요구하는 상황에 적합하지 않음을 알게 되었다.

## Limitations & Future Work

실시간 성능을 위해 궤적에 대한 대략적인 좌표를 샘플링한다. 이로 인해 날카로운 부분이나 일부 작은 장애물 등을 놓치게 된다. 따라서 실제 적용시에는 이를 피해야 한다. 간단한 한 가지 해결책이 있는데 시스템 위에 추가적인 제어 계층을 두어 레이블링된 장애물에 대응 가능하도록 만드는 것이다. 

다른 많은 방법과 마찬가지로 이들이 만든 기술도 벽을 오르거나 물체와 상호작용을 할 때와 같이 정확한 손 움직임이 필요할 때, 이를 잘 처리할 수 없게 된다. 향후에는 손 접촉에 라벨을 붙이고 손에서 IK를 수행하는 것 등을 통해 이를 해결하고자 한다. 

미니배치의 각 요소는 다른 서로 다른 가중치를 생성하므로 훈련 중 계산 비용이 더 많이 들기 때문에 PFNN의 훈련 속도는 상대적으로 느려진다. PFNN은 새로운 데이터가 추가 될 때마다 몇 시간의 훈련 시간이 추가로 소모되었고 이 때문에 훈련 속도를 높이는 것에 많은 관심을 가지고 있었다.

![image](https://user-images.githubusercontent.com/62225673/155294581-f0cd85ce-2cbe-4cf7-812a-e220f82390cf.png)

사용자가 주어진 상황에서 무리한 요구를 입력으로 제시할 경우, 이상한 결과를 산출한다고 한다. 이는 위의 그림을 참고하면 된다.

또 다른 future work는 물리 기반 애니메이션에 PFNN을 적용시켜 보는 것이다. 이러한 시스템을 통해 미끄러운 바닥이나 불안정한 로프 위에서와 같은 다양한 물리적 환경에 대한 안정감 있는 결과를 만들어낼 수 있을 것 같다. 

마지막으로 심장 박동의 주기와 같은 fMRI 등에 이들의 논문을 적용하는 방법도 있다. PFNN과 같은 주기 모델을 이러한 주기적 데이터에 넣는 것은 학습 효율을 높일 수 있다.

# 10. CONCLUSION

이들은 인간의 이동과 같은 주기적인 행동을 생성하는 데 적합한 Phase Function Neural Network를 제안했다. 그리고 복잡한 환경에서 캐릭터 제어가 가능한 네트워크 입력과 출력을 설계했다. 네트워크는 간단한 구조임에도 phase 덕분에 대규모 데이터를 이용한 학습을 통해 부드러운 모션 생성이 가능하다. 또한 이들은 인간의 이동과 지형이 결합한 PFNN 훈련을 위한 추가 데이터 생성을 위한 프레임워크를 제안했다. 일단 훈련을 받으면 시스템은 빠르고 메모리가 거의 필요하지 않으며, 기존 방법에서 발견되는 common artefacts을 보여주지 않고도 고품질의 action을 생성한다.